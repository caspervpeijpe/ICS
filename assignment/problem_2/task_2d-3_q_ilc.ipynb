{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac408b5e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a96d02d6346fa7399cf6da0111ce0937",
     "grade": false,
     "grade_id": "cell-b00828259c8e42e8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# RO47019: Intelligent Control Systems Practical Assignment\n",
    "* Period: 2022-2023, Q3\n",
    "* Course homepage: https://brightspace.tudelft.nl/d2l/home/500969\n",
    "* Instructor: Cosimo Della Santina (C.DellaSantina@tudelft.nl)\n",
    "* Teaching assistant: Ruben Martin Rodriguez (R.MartinRodriguez@student.tudelft.nl)\n",
    "* (c) TU Delft, 2023\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or `YOUR ANSWER HERE`. Remove `raise NotImplementedError()` afterwards. Moreover, if you see an empty cell, please DO NOT delete it, instead run that cell as you would run all other cells. Please fill in your name(s) and other required details below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9e220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please fill in your names, student numbers, netID, and emails below.\n",
    "STUDENT_1_NAME = \"\"\n",
    "STUDENT_1_STUDENT_NUMBER = \"\"\n",
    "STUDENT_1_NETID = \"\"\n",
    "STUDENT_1_EMAIL = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba32571",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "042927213b84aa368aa3ea72caa4cb60",
     "grade": true,
     "grade_id": "cell-9f148ec62e0de49c",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Note: this block is a check that you have filled in the above information.\n",
    "# It will throw an AssertionError until all fields are filled\n",
    "assert STUDENT_1_NAME != \"\"\n",
    "assert STUDENT_1_STUDENT_NUMBER != \"\"\n",
    "assert STUDENT_1_NETID != \"\"\n",
    "assert STUDENT_1_EMAIL != \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af317a94",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e76ef40fcc3f08a0484661497162a1a9",
     "grade": false,
     "grade_id": "cell-4ea391677951116c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### General announcements\n",
    "\n",
    "* Do *not* share your solutions, and do *not* copy solutions from others. By submitting your solutions, you claim that you alone are responsible for this code.\n",
    "\n",
    "* Do *not* email questions directly, since we want to provide everybody with the same information and avoid repeating the same answers. Instead, please post your questions regarding this assignment in the correct support forum on Brightspace, this way everybody can benefit from the response. If you do have a particular question that you want to ask directly, please use the scheduled Q&A hours to ask the TA.\n",
    "\n",
    "* There is a strict deadline for each assignment. Students are responsible to ensure that they have uploaded their work in time. So, please double check that your upload succeeded to the Brightspace and avoid any late penalties.\n",
    "\n",
    "* This [Jupyter notebook](https://jupyter.org/) uses `nbgrader` to help us with automated tests. `nbgrader` will make various cells in this notebook \"uneditable\" or \"unremovable\" and gives them a special id in the cell metadata. This way, when we run our checks, the system will check the existence of the cell ids and verify the number of points and which checks must be run. While there are ways that you can edit the metadata and work around the restrictions to delete or modify these special cells, you should not do that since then our nbgrader backend will not be able to parse your notebook and give you points for the assignment. You are free to add additional cells, but if you find a cell that you cannot modify or remove, please know that this is on purpose.\n",
    "\n",
    "* This notebook will have in various places a line that throws a `NotImplementedError` exception. These are locations where the assignment requires you to adapt the code! These lines are just there as a reminder for youthat you have not yet adapted that particular piece of code, especially when you execute all the cells. Once your solution code replaced these lines, it should accordingly *not* throw any exceptions anymore.\n",
    "\n",
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c956945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f2a65ab",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "159bec29bbfba46080460d1fe8be31f7",
     "grade": false,
     "grade_id": "cell-aa5bffe8b9c390d8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Task 2d.3 - Q-ILC (17.5p)\n",
    "\n",
    "**Author:** Maximilian St√∂lzle (M.W.Stolzle@tudelft.nl)\n",
    "\n",
    "We assume the scenario as in Task 2d.2, but now use Q-ILC instead of PD-ILC. This means, that we leverage LQR to compute the optimal gains $L_\\mathrm{opt}$, instead of manually tuning the proportional and derivative gains used within the ILC learning rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da02667",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bfabdbf7dbaf9097b99fd797b609e25f",
     "grade": false,
     "grade_id": "cell-caae196fd2bdb370",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Reloads the python files outside of this notebook automatically\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from distutils.util import strtobool\n",
    "from functools import partial\n",
    "from IPython.display import display, HTML  # For animations in the notebook\n",
    "from jax.config import config as jax_config\n",
    "\n",
    "jax_config.update(\"jax_platform_name\", \"cpu\")  # set default device to 'cpu'\n",
    "jax_config.update(\"jax_enable_x64\", True)  # double precision\n",
    "from jax import debug, jacfwd, jit, lax, vmap\n",
    "import jax.numpy as jnp\n",
    "from jax.scipy import linalg\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Callable, Dict, Tuple\n",
    "\n",
    "from jax_double_pendulum.motion_planning import (\n",
    "    generate_ellipse_trajectory,\n",
    "    ELLIPSE_PARAMS,\n",
    ")\n",
    "from jax_double_pendulum.robot_parameters import ROBOT_PARAMS\n",
    "\n",
    "from ilc import init_ilc_its, apply_ilc_control_action_to_system\n",
    "\n",
    "# import linearize_closed_loop_fb_system_about_trajectory from linearization.ipynb\n",
    "from ipynb.fs.full.linearization import cont2discrete_zoh\n",
    "\n",
    "# import linearize_closed_loop_fb_system_about_trajectory from linearization.ipynb\n",
    "from ipynb.fs.full.linearization import linearize_closed_loop_fb_system_about_trajectory\n",
    "\n",
    "# define boolean to check if the notebook is run for the purposes of autograding\n",
    "AUTOGRADING = strtobool(os.environ.get(\"AUTOGRADING\", \"false\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1edb235",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3ae75ece477d713884c172cf13cbd535",
     "grade": false,
     "grade_id": "cell-a5567fb1cbf961e5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Lifted system input to state mapping (5p)\n",
    "\n",
    "The goal of this task is compute the matrix $P \\in \\mathbb{R}^{2 (N-1) \\times 2 (N-1)}$, which maps in the lifted system the sequence of inputs $U \\in \\mathbb{R}^{2 (N-1)}$ to the sequence of outputs $Y \\in \\mathbb{R}^{2 (N-1)}$. It is essential for computing the optimal gains $L$ as part of Q-ILC.\n",
    "Please note as the linearization of the system does not change through the iterations, this matrix $P$ only needs to be computed *once* before the start of the Q-ILC algorithm.\n",
    "\n",
    "The function `compute_lifted_system_input_to_output_mapping` shall take state-space matrices discretized about each point of the desired trajectory (i.e. $A_d^k$, $B_d^k$, $C_d^k$, and $D_d^k$) as an input and return P. Please be aware that the computational complexity of this computation is higher than $\\mathcal{O}((N-1)^2)$. Therefore, we strongly advise to make use of the jittable JAX function [`lax.fori_loop`](https://jax.readthedocs.io/en/latest/_autosummary/jax.lax.fori_loop.html) instead of normal Python `for` loops, which are much slower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400cb2c8",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "601f40adef5d7a08759188ba45add1b7",
     "grade": false,
     "grade_id": "cell-f4ec51d27b7eeca0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_lifted_system_input_to_output_mapping(\n",
    "    Ad_ts: jnp.ndarray, Bd_ts: jnp.ndarray, Cd_ts: jnp.ndarray, Dd_ts: jnp.ndarray\n",
    ") -> jnp.ndarray:\n",
    "    \"\"\"\n",
    "    Compute the matrix P in super-vector notation relating the input to the output of the lifted system:\n",
    "        Y = H + P @ U\n",
    "    Args:\n",
    "        Ad_ts: discrete-time state transition matrix of shape (N, 4, 4)\n",
    "        Bd_ts: discrete-time input matrix of shape (N, 4, 2)\n",
    "        Cd_ts: discrete-time output matrix of shape (N, 2, 4)\n",
    "        Dd_ts: discrete-time feed-through matrix of shape (N, 2, 2)\n",
    "    Returns:\n",
    "        P: matrix with Markov parameters of shape (2*(N-1), 2*(N-1))\n",
    "    \"\"\"\n",
    "    print(\"Computing P matrix...\")\n",
    "\n",
    "    N = Ad_ts.shape[0]  # number of time steps\n",
    "    m = Ad_ts.shape[-1]  # state dimension: should be 4\n",
    "    n = Bd_ts.shape[-1]  # input dimension: should be 2\n",
    "    o = Cd_ts.shape[-2]  # output dimension: should be 2\n",
    "\n",
    "    # initialize the matrix with zeros\n",
    "    P = jnp.zeros(((N - 1) * o, (N - 1) * n))\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    print(\"Finished computation of P matrix!\")\n",
    "\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e70a4a5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4aa6cf071222e7ac6e71ad5d610efa2d",
     "grade": false,
     "grade_id": "cell-c34ea3b70d96dffb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# define time steps\n",
    "_duration = 4.0  # [s]\n",
    "_dt = 1  # s\n",
    "_t_ts = _dt * jnp.arange(int(_duration / _dt))\n",
    "\n",
    "# generate trajectory\n",
    "_traj_ts = generate_ellipse_trajectory(\n",
    "    rp=ROBOT_PARAMS,\n",
    "    t_ts=_t_ts,\n",
    "    **ELLIPSE_PARAMS,\n",
    ")\n",
    "\n",
    "# linearize and discretize the closed-loop system about trajectory\n",
    "(\n",
    "    _tau_eq_ts,\n",
    "    _Ad_ts,\n",
    "    _Bd_ts,\n",
    "    _Cd_ts,\n",
    "    _Dd_ts,\n",
    ") = linearize_closed_loop_fb_system_about_trajectory(\n",
    "    ROBOT_PARAMS,\n",
    "    _traj_ts,\n",
    "    kp_fb=500 * jnp.eye(2),\n",
    "    kd_fb=50 * jnp.eye(2),\n",
    ")\n",
    "\n",
    "# compute P matrix\n",
    "_P = compute_lifted_system_input_to_output_mapping(_Ad_ts, _Bd_ts, _Cd_ts, _Dd_ts)\n",
    "with jnp.printoptions(precision=4):\n",
    "    print(\"Computed P matrix:\\n\", _P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9cdb02",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0971ca68ca6d9a91dcc53b52e8534a79",
     "grade": true,
     "grade_id": "cell-4f573273c0bf39eb",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT REMOVE OR MODIFY THIS CELL\n",
    "\n",
    "# test if your solution for the `P` matrix is correct\n",
    "_P_target = jnp.array(\n",
    "    [\n",
    "        [\n",
    "            4.69474793e-03,\n",
    "            4.84245357e-05,\n",
    "            0.00000000e00,\n",
    "            0.00000000e00,\n",
    "            0.00000000e00,\n",
    "            0.00000000e00,\n",
    "        ],\n",
    "        [\n",
    "            8.99674986e-05,\n",
    "            1.96726866e-03,\n",
    "            0.00000000e00,\n",
    "            0.00000000e00,\n",
    "            0.00000000e00,\n",
    "            0.00000000e00,\n",
    "        ],\n",
    "        [\n",
    "            -1.98004699e-03,\n",
    "            9.25264174e-05,\n",
    "            4.58032646e-03,\n",
    "            -1.15100224e-04,\n",
    "            0.00000000e00,\n",
    "            0.00000000e00,\n",
    "        ],\n",
    "        [\n",
    "            4.58959880e-05,\n",
    "            -8.44664130e-06,\n",
    "            -6.28302345e-05,\n",
    "            2.00715823e-03,\n",
    "            0.00000000e00,\n",
    "            0.00000000e00,\n",
    "        ],\n",
    "        [\n",
    "            1.15066310e-03,\n",
    "            -3.31164677e-05,\n",
    "            -2.21814480e-03,\n",
    "            2.04762711e-04,\n",
    "            2.60964753e-03,\n",
    "            -2.87025682e-04,\n",
    "        ],\n",
    "        [\n",
    "            -2.59137236e-04,\n",
    "            1.05803119e-05,\n",
    "            5.63800885e-04,\n",
    "            -5.71102501e-05,\n",
    "            -2.90142700e-04,\n",
    "            2.22991768e-03,\n",
    "        ],\n",
    "    ]\n",
    ")\n",
    "with jnp.printoptions(precision=4):\n",
    "    print(\"Target P matrix:\\n\", _P_target)\n",
    "assert jnp.allclose(_P_target, _P)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9369086c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e538335b3c5a514f6d2a1a63f300757e",
     "grade": false,
     "grade_id": "cell-8c4c26ce24aa5741",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Computation of the optimal gains (3.5p)\n",
    "\n",
    "Below, you should compute the optimal gains $L_\\mathrm{opt} \\in \\mathbb{R}^{2(N-1) \\times 2(N-1)}$ for the ILC algorithm while taking into account the two cost weight matrices $Q_\\mathrm{lq} \\in \\mathbb{R}^{2(N-1) \\times 2(N-1)}$ and $S_\\mathrm{lq} \\in \\mathbb{R}^{2(N-1) \\times 2(N-1)}$\n",
    "\n",
    "\\begin{equation}\n",
    "    L_\\mathrm{opt} = (P^\\mathrm{T} \\: Q_\\mathrm{lq} \\: P + S_\\mathrm{lq})^{-1}) \\: P^\\mathrm{T} \\: Q_\\mathrm{lq}.\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a347e56",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b9fbbb312350240b0ddab08d37d4be7e",
     "grade": false,
     "grade_id": "cell-6bb385b94038ed87",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_lqr_optimal_gains(\n",
    "    P: jnp.ndarray,\n",
    "    Q_lq: jnp.ndarray = None,\n",
    "    S_lq: jnp.ndarray = None,\n",
    ") -> jnp.ndarray:\n",
    "    \"\"\"\n",
    "    Compute the optimal gains L_opt for the Q-ILC algorithm\n",
    "    Args:\n",
    "        P: matrix with Markov parameters of shape (2 * (N - 1), 2 * (N - 1))\n",
    "        Q_lq: Cost weight on the tracking error of shape (2 * (N - 1), 2 * (N - 1))\n",
    "        S_lq: Cost weight on changing the ILC actions in between iterations (2*(N-1), 2*(N-1))\n",
    "            (i.e. penalizing large changes in the control action over time)\n",
    "\n",
    "    Returns:\n",
    "        L_opt: optimal gains for the Q-ILC algorithm of shape (2 * (N - 1), 2 * (N - 1))\n",
    "\n",
    "    \"\"\"\n",
    "    # Cost weight on the tracking error\n",
    "    if Q_lq is None:\n",
    "        Q_lq = jnp.zeros((P.shape[0], P.shape[0]))\n",
    "    assert Q_lq.shape == (\n",
    "        P.shape[0],\n",
    "        P.shape[0],\n",
    "    ), \"Q_lq should be a square matrix of shape (2*(N-1), 2*(N-1))\"\n",
    "\n",
    "    # Cost weight on changing the ILC actions in between iterations\n",
    "    if S_lq is None:\n",
    "        S_lq = 1e0 * jnp.eye(P.shape[1])\n",
    "    assert S_lq.shape == (\n",
    "        P.shape[1],\n",
    "        P.shape[1],\n",
    "    ), \"S_lq should be a square matrix of shape (2*(N-1), 2*(N-1))\"\n",
    "\n",
    "    # Compute optimal gains\n",
    "    L_opt = jnp.zeros_like(P.transpose())\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    return L_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125846c9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c1fbecc11b1cb3c944bf58f9764c2a3c",
     "grade": true,
     "grade_id": "cell-4978fd34be215e19",
     "locked": true,
     "points": 1.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT REMOVE OR MODIFY THIS CELL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114c8c6f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d21781b5400797f115937943828a1ac6",
     "grade": false,
     "grade_id": "Q1-question",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 1\n",
    "\n",
    "Was is the effect on the ILC convergence of increasing the magnitude of $S_\\mathrm{lq}$ while keeping $Q_\\mathrm{lq}$ constant? **Hint:** study the formula for the optimal gain.\n",
    "\n",
    "**A:** No effect\n",
    "\n",
    "**B:** Faster convergence\n",
    "\n",
    "**C:** Slower convergence\n",
    "\n",
    "**D:** Less numerical stability\n",
    "\n",
    "**E:** An increased regularization of the system inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6997839",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b7e35b6d91cd62ed355daf56241c3459",
     "grade": false,
     "grade_id": "Q1-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# please write the answer (\"A\", \"B\", \"C\", \"D\", or \"E\") into the `answer_1` variable\n",
    "answer_1 = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12386f6e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c595e06045f5fcfaa1a444f0fec41581",
     "grade": true,
     "grade_id": "Q1-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT REMOVE OR MODIFY THIS CELL\n",
    "assert answer_1 in [\"A\", \"B\", \"C\", \"D\", \"E\"], 'Please answer \"A\", \"B\", \"C\", \"D\", or \"E\"'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d125c5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9a4017f9fa1cfb38f59db3ea43565c93",
     "grade": false,
     "grade_id": "Q2-question",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 2\n",
    "\n",
    "Was is the effect on the ILC convergence of increasing the magnitude of $S_\\mathrm{lq}$ and $Q_\\mathrm{lq}$ by the same factor $a$? **Hint:** study the formula for the optimal gain.\n",
    "\n",
    "\\begin{equation}\n",
    "    S_\\mathrm{lq,new} = a \\: S_\\mathrm{lq,old} \\qquad Q_\\mathrm{lq,new} = a \\: Q_\\mathrm{lq,old}\n",
    "\\end{equation}\n",
    "\n",
    "**A:** No effect\n",
    "\n",
    "**B:** Faster convergence\n",
    "\n",
    "**C:** Slower convergence\n",
    "\n",
    "**D:** Less numerical stability\n",
    "\n",
    "**E:** An increased regularization of the magnitude of the system inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b29374",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9506fa0e17e83d512b27871e9118921f",
     "grade": false,
     "grade_id": "Q2-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# please write the answer (\"A\", \"B\", \"C\", \"D\", or \"E\") into the `answer_2` variable\n",
    "answer_2 = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b73694",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3e6ab1c07e2a883553694f5f51558dd9",
     "grade": true,
     "grade_id": "Q2-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT REMOVE OR MODIFY THIS CELL\n",
    "assert answer_2 in [\"A\", \"B\", \"C\", \"D\", \"E\"], 'Please answer \"A\", \"B\", \"C\", \"D\", or \"E\"'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca67541b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4fb9cdbbd559823968347d1a4f9f301f",
     "grade": false,
     "grade_id": "cell-00a8a054d04f9997",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Learning rule (2p)\n",
    "\n",
    "Now, please implement the learning rule for Q-ILC, which in super-vector notation can be expressed as\n",
    "\n",
    "\\begin{equation}\n",
    "    U_{j+1} = U_{j} + L_\\mathrm{opt} \\: E\n",
    "\\end{equation}\n",
    "\n",
    "where $U \\in \\mathbb{R}^{2 (N-1)}$ is the time sequence of system inputs and $E \\in \\mathbb{R}^{2 (N-1)}$ is the error between the desired and the actual system outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c51e7f6",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "da3382fdc8d6e65c99e01aba1a4da271",
     "grade": false,
     "grade_id": "cell-647f143e5a269969",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def learning_rule_q_ilc(\n",
    "    u_ts: jnp.ndarray,\n",
    "    y_ts: jnp.ndarray,\n",
    "    y_des_ts: jnp.ndarray,\n",
    "    L_opt: jnp.ndarray,\n",
    ") -> jnp.array:\n",
    "    \"\"\"\n",
    "    Implements the PD-ILC learning rule to compute the ILC control action `U_next` for the next iteration\n",
    "\n",
    "    Args:\n",
    "        u_ts: array of shape (N, 2) containing the ILC actions at the current iteration\n",
    "        y_ts: array of shape (N, 2) containing the system outputs at the current iteration\n",
    "        y_des_ts: array of shape (N, 2) containing the desired system outputs\n",
    "        L_opt: optimal gains for the Q-ILC algorithm of shape (2 * (N - 1), 2 * (N - 1))\n",
    "\n",
    "    Returns:\n",
    "        u_nextit_ts: array of shape (N, 2) containing the ILC actions at the next iteration\n",
    "    \"\"\"\n",
    "    # number of time-steps\n",
    "    N = u_ts.shape[0]\n",
    "\n",
    "    # extract the last (N-1) time-steps of the outputs and transform to super-vector notation\n",
    "    Y = jnp.zeros((2 * (N - 1)))\n",
    "    Y_des = jnp.zeros_like(Y)\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    # compute the output error E of the last (N-1) time-steps in super-vector notation\n",
    "    E = jnp.zeros_like(Y)\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    # extract the first (N-1) time-steps of the ILC actions and transform to super-vector notation\n",
    "    U = jnp.zeros((2 * (N - 1)))\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    # implement the Q-ILC learning rule and compute the ILC action at the next iteration `U_nextit`\n",
    "    # should be array of shape (2 * (N-1), ) in super-vector notation\n",
    "    U_nexit = jnp.zeros_like(U)\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    # transform `U_nexit` from super-vector notation to array `u_nexit_ts` of shape (N, 2)\n",
    "    # Hint: the control action at the last time-step is always zero\n",
    "    # as it does not have an influence on the system states within the given time horizon\n",
    "    u_nextit_ts = jnp.zeros_like(u_ts)\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    return u_nextit_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331f0f47",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c92f706d4115ad78b3cdc59e582e9480",
     "grade": true,
     "grade_id": "cell-3d05810955b26c48",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT REMOVE OR MODIFY THIS CELL\n",
    "_y_ts = jnp.arange(10, dtype=jnp.double).reshape((-1, 2))\n",
    "_y_des_ts = jnp.arange(start=10, step=-1, stop=0, dtype=jnp.double).reshape((-1, 2))\n",
    "_u_ts = jnp.arange(0, 10, dtype=jnp.double).reshape((5, 2))\n",
    "_N = _y_ts.shape[0]  # number of time-steps\n",
    "_L_opt = jnp.diag(jnp.arange(2 * (_N - 1), dtype=jnp.double))\n",
    "\n",
    "_u_nextit_ts = learning_rule_q_ilc(_u_ts, _y_ts, _y_des_ts, _L_opt)\n",
    "print(\"Computed ILC action at the next iteration:\\n\", _u_nextit_ts)\n",
    "\n",
    "# target for next ILC actuation sequence\n",
    "_u_nextit_ts_target = jnp.array(\n",
    "    [\n",
    "        [0.0, 5.0],\n",
    "        [6.0, 3.0],\n",
    "        [-4.0, -15.0],\n",
    "        [-30.0, -49.0],\n",
    "        [0.0, 0.0],\n",
    "    ]\n",
    ")\n",
    "print(\"Target ILC action at the next iteration:\\n\", _u_nextit_ts_target)\n",
    "\n",
    "# make sure that the results of your implementation matches the target\n",
    "assert jnp.allclose(_u_nextit_ts_target, _u_nextit_ts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104d3afe",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b89538144612c47b1e17abe01c940d4b",
     "grade": false,
     "grade_id": "cell-94b11d5995fd1680",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Implementation of Q-ILC\n",
    "\n",
    "Now, we will implement the main function(s) to bring everything together and run Q-ILC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921397d2",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7e50a7f0edc699cc542ebf338b2bbd88",
     "grade": false,
     "grade_id": "cell-411b289c4a76100b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def run_q_ilc(\n",
    "    rp: dict,\n",
    "    traj_ts: Dict[str, jnp.ndarray],\n",
    "    th_0: jnp.ndarray,\n",
    "    th_d_0: jnp.ndarray,\n",
    "    num_iterations: int,\n",
    "    tau_eq_ts: jnp.ndarray,\n",
    "    P: jnp.ndarray,\n",
    "    Q_lq: jnp.ndarray = None,\n",
    "    S_lq: jnp.ndarray = None,\n",
    "    kp_fb: jnp.ndarray = jnp.zeros((2, 2)),\n",
    "    kd_fb: jnp.ndarray = jnp.zeros((2, 2)),\n",
    "    rp_perturbed: dict = None,\n",
    ") -> Dict[str, jnp.ndarray]:\n",
    "    \"\"\"\n",
    "    Run the Q-ILC algorithm to track a desired trajectory\n",
    "    Args:\n",
    "        rp: dictionary of robot parameters\n",
    "        traj_ts: dictionary of time series of trajectories\n",
    "        th_0: initial link angles of shape (2,)\n",
    "        th_d_0: initial link angular velocities of shape (2,)\n",
    "        num_iterations: number of iterations of the Q-ILC algorithm\n",
    "        tau_eq_ts: time series of equilibrium torques of shape (N, 2)\n",
    "        P: matrix with Markov parameters of shape (2*(N-1), 2*(N-1))\n",
    "        Q_lq: Cost matrix for the tracking error (i.e. proportional term) of shape (2*(N-1), 2*(N-1))\n",
    "        S_lq: Cost matrix for any change in control action of shape (2*(N-1), 2*(N-1))\n",
    "            (i.e. penalizing large changes in the control action over time)\n",
    "        kp_fb: proportional gains of the parallel feedback controller of shape (2, 2)\n",
    "        kd_fb: derivative gains of the parallel feedback controller of shape (2, 2)\n",
    "        rp_perturbed: dictionary of perturbed robot parameters used for linearizing the model and computing the\n",
    "            trajectory equilibrium torque. If not specified, the nominal robot parameters are used.\n",
    "    Returns:\n",
    "        ilc_its: dictionary to track states across iterations and time steps\n",
    "    \"\"\"\n",
    "    print(\"Computing the Q-ILC gains...\")\n",
    "    L_opt = compute_lqr_optimal_gains(P, Q_lq, S_lq)\n",
    "\n",
    "    # we estimate the ILC control action initially to be zero\n",
    "    # the torque at the last time index is always zero and never applied to the system\n",
    "    u_ts = jnp.zeros_like(tau_eq_ts)\n",
    "\n",
    "    # initialize the dictionary to save iterations\n",
    "    ilc_its = init_ilc_its(num_iterations, traj_ts)\n",
    "    ilc_its[\"tau_eq_ts\"] = tau_eq_ts\n",
    "    ilc_its[\"u_nextit_ts\"] = u_ts\n",
    "    ilc_its[\"L_opt\"] = L_opt\n",
    "\n",
    "    print(\"Running the Q-ILC algorithm...\")\n",
    "    # Implement here your code for looping through the ILC iterations and write the data into `ilc_its`\n",
    "    # Hint: you can take inspiration for this from the previous task(s)\n",
    "    # ilc_its = lax.fori_loop ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    # remove u_ts_next_it entries only needed for the loop\n",
    "    ilc_its.pop(\"u_nextit_ts\")\n",
    "\n",
    "    return ilc_its\n",
    "\n",
    "\n",
    "@jit\n",
    "def q_ilc_iteration(\n",
    "    rp: dict,\n",
    "    traj_ts: Dict[str, jnp.ndarray],\n",
    "    th_0: jnp.ndarray,\n",
    "    th_d_0: jnp.ndarray,\n",
    "    tau_eq_ts: jnp.ndarray,\n",
    "    L_opt: jnp.ndarray,\n",
    "    kp_fb: jnp.ndarray,\n",
    "    kd_fb: jnp.ndarray,\n",
    "    it: int,\n",
    "    ilc_its: Dict[str, jnp.ndarray],\n",
    ") -> Dict[str, jnp.ndarray]:\n",
    "    \"\"\"\n",
    "    Perform one iteration of the Q-ILC algorithm\n",
    "\n",
    "    Args:\n",
    "        rp: dictionary of robot parameters\n",
    "        traj_ts: dictionary of time series of trajectories\n",
    "        th_0: initial link angles of shape (2,)\n",
    "        th_d_0: initial link angular velocities of shape (2,)\n",
    "        tau_eq_ts: time series of equilibrium torques of shape (N, 2)\n",
    "        L_opt: optimal gains for the Q-ILC algorithm of shape ((N - 1) * 2, (N - 1) * 2)\n",
    "        kp_fb: proportional gains of the parallel feedback controller of shape (2, 2)\n",
    "        kd_fb: derivative gains of the parallel feedback controller of shape (2, 2)\n",
    "        it: iteration index\n",
    "        ilc_its: dictionary to track states across iterations and time steps\n",
    "    Returns:\n",
    "        ilc_its: updated dictionary to track states across iterations and time steps\n",
    "    \"\"\"\n",
    "    # Read-out the ILC action `u_ts` computed at the end of the last iteration\n",
    "    u_ts = ilc_its[\"u_nextit_ts\"]\n",
    "    ilc_its[\"u_its\"] = ilc_its[\"u_its\"].at[it].set(u_ts)\n",
    "\n",
    "    # Compute the feedforward torque sequence `tau_ilc_t` as a sum of\n",
    "    # the equilbrium torque and the ILC control action\n",
    "    tau_ilc_ts = jnp.zeros_like(tau_eq_ts)\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    # simulate the system with the current control action\n",
    "    sim_ts, ilc_its = apply_ilc_control_action_to_system(\n",
    "        rp=rp,\n",
    "        traj_ts=traj_ts,\n",
    "        th_0=th_0,\n",
    "        th_d_0=th_d_0,\n",
    "        it=it,\n",
    "        ilc_its=ilc_its,\n",
    "        tau_ilc_ts=tau_ilc_ts,\n",
    "        kp_fb=kp_fb,\n",
    "        kd_fb=kd_fb,\n",
    "    )\n",
    "\n",
    "    # Call the Q-ILC learning rule\n",
    "    # Hint: the sequence of link angles is stored in the `traj_ts` and `sim_ts` dictionaries.\n",
    "    u_nextit_ts = jnp.zeros_like(u_ts)\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    # Store the ILC action for the next iteration in the dictionary\n",
    "    ilc_its[\"u_nextit_ts\"] = u_nextit_ts\n",
    "\n",
    "    return ilc_its"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740e0fc2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "21e636398b68bcf72a2c1b38b44396c7",
     "grade": false,
     "grade_id": "cell-a30fbe6d31310bb8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Let's run it (7p)\n",
    "\n",
    "Now, let's actually run Q-ILC. Analogue to PD-ILC, we will use the perturbed robot parameters to derive the control law(s) and the nominal robot model to simulate the double pendulum.\n",
    "\n",
    "For the PD feedback controller, we set the gains to $k_\\mathrm{p} = \\mathrm{diag}(500, 500)$ Nm / rad and $k_\\mathrm{d} = \\mathrm{diag}(50, 50)$ Nm s / rad. The Q-ILC cost weight matrices `Q_lq` and `S_lq` are set to a magnitude of $1$ and $5 \\cdot 10^{-4}$ respectively.\n",
    "\n",
    "**You will notice, that for the initial pertubation factor of `perturbation_factor = 3`, which determines the magnitude of the mismatch between linearization and nominal robot model, the Q-ILC algorithm does not converge.** What is the reason for this observed behaviour?\n",
    "\n",
    "Please choose the **highest** perturbation factor, which allows for ILC convergence. We assume ILC convergence, if **the Euclidean norm of the RMSE of the end-effector position error is below 0.04 m.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6d1b34",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "350b6764a377f913e297092ed1f35453",
     "grade": false,
     "grade_id": "cell-9dd0544eb9e66b6f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from jax_double_pendulum.analysis import *\n",
    "from jax_double_pendulum.robot_simulation import simulate_robot\n",
    "from jax_double_pendulum.utils import normalize_link_angles\n",
    "from jax_double_pendulum.visualization import animate_robot\n",
    "\n",
    "from ilc_analysis import (\n",
    "    plot_configuration_space_ilc_convergence,\n",
    "    animate_configuration_space_trajectory_following_plot,\n",
    "    animate_operational_space_trajectory_following_plot,\n",
    "    animate_actuation_plot,\n",
    ")\n",
    "\n",
    "# path for caching the P matrix and tau_eq_ts\n",
    "cache_path = Path(\"cache\") / \"q_ilc.npz\"\n",
    "\n",
    "# define folder where to save animations and plots\n",
    "outputs_dir = Path(\"outputs\")\n",
    "outputs_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# simulation parameters\n",
    "sim_duration = 10.0  # [s]\n",
    "sim_dt = 1e-2  # [s]\n",
    "\n",
    "# define time steps\n",
    "t_ts = sim_dt * jnp.arange(int(sim_duration / sim_dt))\n",
    "\n",
    "# gains of parallel feedback PD controller\n",
    "# IMPORTANT: you are not allowed to change the feedback PD gains!!!\n",
    "kp_fb = 500 * jnp.eye(2)  # [Nm/rad]\n",
    "kd_fb = 50 * jnp.eye(2)  # [Nm s/rad]\n",
    "\n",
    "# number of ILC iterations\n",
    "num_ilc_iterations = 1000\n",
    "\n",
    "# ILC-LQR controller gains\n",
    "Q_lq = 1e0 * jnp.eye(2 * (t_ts.shape[0] - 1))\n",
    "S_lq = 5e-4 * jnp.eye(2 * (t_ts.shape[0] - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b751b1cf",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ea01699274ffb4a977ba2d3f97635f87",
     "grade": false,
     "grade_id": "cell-acebd6af14daf366",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# the pertubation factor determines by how much the masses and inertia of the perturbed robot model\n",
    "# used for control is increased with respect to the actual / nominal systems (i.e. in our case used for simulation)\n",
    "perturbation_factor = 3\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb837cc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b74d597eac1424cdd0e0fcbe86fe62eb",
     "grade": false,
     "grade_id": "cell-475d3f3070556965",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# robot parameters\n",
    "rp = ROBOT_PARAMS\n",
    "\n",
    "# perturbed robot parameters used for linearizing the system\n",
    "rp_perturbed = rp.copy()\n",
    "rp_perturbed.update(\n",
    "    {\n",
    "        \"m1\": perturbation_factor * rp[\"m1\"],\n",
    "        \"j1\": perturbation_factor * rp[\"j1\"],\n",
    "        \"m2\": perturbation_factor * rp[\"m2\"],\n",
    "        \"j2\": perturbation_factor * rp[\"j2\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "# generate ellipse trajectory\n",
    "traj_ts = generate_ellipse_trajectory(\n",
    "    rp=rp,\n",
    "    t_ts=t_ts,\n",
    "    **ELLIPSE_PARAMS,\n",
    ")\n",
    "\n",
    "# specify the initial link angles at the beginning of each simulation\n",
    "th_0 = traj_ts[\"th_ts\"][0] - jnp.array([0.1, 0.2])\n",
    "\n",
    "# linearize the system\n",
    "(\n",
    "    tau_eq_ts,\n",
    "    Ad_ts,\n",
    "    Bd_ts,\n",
    "    Cd_ts,\n",
    "    Dd_ts,\n",
    ") = linearize_closed_loop_fb_system_about_trajectory(\n",
    "    rp_perturbed, traj_ts, kp_fb, kd_fb\n",
    ")\n",
    "\n",
    "# compute the P matrix\n",
    "P = compute_lifted_system_input_to_output_mapping(Ad_ts, Bd_ts, Cd_ts, Dd_ts)\n",
    "\n",
    "# save to cache\n",
    "jnp.savez(str(cache_path), tau_eq_ts=tau_eq_ts, P=P)\n",
    "\n",
    "print(\"Saved tau_eq_ts and P to cache at\", str(cache_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d48ce95",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "36848ba6209dfe554a946bcdab84871d",
     "grade": false,
     "grade_id": "cell-e53dcf87f9cc4eea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "if cache_path.exists():\n",
    "    print(\"Loading tau_eq_ts and P from cache...\")\n",
    "    cache_data = jnp.load(str(cache_path))\n",
    "    tau_eq_ts, P = cache_data[\"tau_eq_ts\"], cache_data[\"P\"]\n",
    "\n",
    "ilc_its = run_q_ilc(\n",
    "    rp=rp,\n",
    "    traj_ts=traj_ts,\n",
    "    th_0=th_0,\n",
    "    th_d_0=traj_ts[\"th_d_ts\"][0],\n",
    "    num_iterations=num_ilc_iterations,\n",
    "    tau_eq_ts=tau_eq_ts,\n",
    "    P=P,\n",
    "    Q_lq=Q_lq,\n",
    "    S_lq=S_lq,\n",
    "    kp_fb=kp_fb,\n",
    "    kd_fb=kd_fb,\n",
    "    rp_perturbed=rp_perturbed,\n",
    ")\n",
    "\n",
    "# plot configuration-space ILC convergence\n",
    "plot_configuration_space_ilc_convergence(\n",
    "    traj_ts,\n",
    "    ilc_its,\n",
    "    show=True,\n",
    "    filepath=str(outputs_dir / \"task_2d-3_ilc_convergence.pdf\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0a66fd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9c9f1cc11bfa9123806712feb2575f53",
     "grade": false,
     "grade_id": "cell-ba8923b179694f80",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# animate the configuration-space evolution through the iterations\n",
    "if not AUTOGRADING:\n",
    "    ani_configuration_space = animate_configuration_space_trajectory_following_plot(\n",
    "        traj_ts,\n",
    "        ilc_its,\n",
    "        max_num_animated_its=50,\n",
    "        show=False,\n",
    "        filepath=str(\n",
    "            outputs_dir / \"task_2d-3_ilc_configuration_space_trajectory_following.mp4\"\n",
    "        ),\n",
    "    )\n",
    "    display(HTML(ani_configuration_space.to_html5_video()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3ce0a9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dd0f0b12298eb763e4e1395b86f94c0c",
     "grade": false,
     "grade_id": "cell-4a00980495abc5d7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# animate the configuration-space evolution through the iterations\n",
    "if not AUTOGRADING:\n",
    "    ani_operational_space = animate_operational_space_trajectory_following_plot(\n",
    "        traj_ts,\n",
    "        ilc_its,\n",
    "        max_num_animated_its=50,\n",
    "        show=False,\n",
    "        filepath=str(\n",
    "            outputs_dir / \"task_2d-3_ilc_operational_space_trajectory_following.mp4\"\n",
    "        ),\n",
    "    )\n",
    "    display(HTML(ani_operational_space.to_html5_video()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40d58e7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "00a387bb7ce5f4a227959960ee7081a0",
     "grade": false,
     "grade_id": "cell-b1238b4d5e40c847",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# animation the actuation sequence through the iterations\n",
    "if not AUTOGRADING:\n",
    "    ani_actuation = animate_actuation_plot(\n",
    "        traj_ts,\n",
    "        ilc_its,\n",
    "        max_num_animated_its=50,\n",
    "        show=False,\n",
    "        filepath=str(outputs_dir / \"task_2d-3_ilc_actuation.mp4\"),\n",
    "    )\n",
    "    display(HTML(ani_actuation.to_html5_video()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab82f63",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "655a8dd64a1e3b6e8565efe07518ffd7",
     "grade": false,
     "grade_id": "cell-478890e3d6436ead",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# import feedback controller from controllers.ipynb\n",
    "from ipynb.fs.full.controllers import ctrl_fb_pd\n",
    "\n",
    "# First, extract the feed-forward torques from the last ILC iteration.\n",
    "# Then, simulate the system again using those torques and a PD feedback controller\n",
    "# and save the system states to `sim_ts`.\n",
    "# Hint: the feed-forward torques of shape (num_ilc_its, num_timesteps, 2) are accessible via\n",
    "# `ilc_its[\"tau_ilc_its\"]` and should be passed to the `tau_ext_ts` argument of the simulation method.\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# plot the configuration-space evolution\n",
    "plot_configuration_space_trajectory_following(\n",
    "    traj_ts,\n",
    "    sim_ts,\n",
    "    filepath=str(\n",
    "        outputs_dir / \"task_2d-3_configuration_space_trajectory_following.pdf\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cfd60f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ad61c5ba0ef6e3d2af5660a73048ad5c",
     "grade": false,
     "grade_id": "cell-febdeb990195f1fc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "rmse_th, rmse_th_d, rmse_th_dd = compute_configuration_space_rmse(traj_ts, sim_ts)\n",
    "rmse_x, rmse_x_d, rmse_x_dd = compute_operational_space_rmse(traj_ts, sim_ts)\n",
    "with jnp.printoptions(precision=3):\n",
    "    print(\n",
    "        \"RMSE theta:\",\n",
    "        rmse_th,\n",
    "        \"rad, RMSE theta_d:\",\n",
    "        rmse_th_d,\n",
    "        \"rad/s, RMSE theta_dd:\",\n",
    "        rmse_th_dd,\n",
    "        \"rad/s^2\",\n",
    "    )\n",
    "    print(\n",
    "        \"RMSE x:\",\n",
    "        f\"{jnp.linalg.norm(rmse_x):.4f}\",\n",
    "        \"m, RMSE x_d:\",\n",
    "        f\"{jnp.linalg.norm(rmse_x_d):.3f}\",\n",
    "        \"m/s, RMSE x_dd:\",\n",
    "        f\"{jnp.linalg.norm(rmse_x_dd):.2f}\",\n",
    "        \"m/s^2\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f16a25",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aaacd683e0718c453851b36b4e552582",
     "grade": true,
     "grade_id": "cell-2242235427d1a3e6",
     "locked": true,
     "points": 7,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT REMOVE OR MODIFY THIS CELL\n",
    "\n",
    "assert (\n",
    "    jnp.linalg.norm(rmse_x) < 0.04\n",
    ")  # The end-effector error needs to be smaller than 0.04 m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9481b91f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "35260199312ede2baa852698497ea0f9",
     "grade": false,
     "grade_id": "cell-24dda8251064706a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# animate this simulation\n",
    "if not AUTOGRADING:\n",
    "    ani_robot = animate_robot(\n",
    "        rp_perturbed,\n",
    "        traj_ts=traj_ts,\n",
    "        sim_ts=sim_ts,\n",
    "        step_skip=5,\n",
    "        show=False,\n",
    "        filepath=str(outputs_dir / \"task_2d-3_controlled_robot.mp4\"),\n",
    "    )\n",
    "    display(HTML(ani_robot.to_html5_video()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d9339a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
