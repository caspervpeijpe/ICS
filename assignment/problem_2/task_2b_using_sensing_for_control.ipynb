{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac408b5e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a96d02d6346fa7399cf6da0111ce0937",
     "grade": false,
     "grade_id": "cell-b00828259c8e42e8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# RO47019: Intelligent Control Systems Practical Assignment\n",
    "* Period: 2022-2023, Q3\n",
    "* Course homepage: https://brightspace.tudelft.nl/d2l/home/500969\n",
    "* Instructor: Cosimo Della Santina (C.DellaSantina@tudelft.nl)\n",
    "* Teaching assistant: Ruben Martin Rodriguez (R.MartinRodriguez@student.tudelft.nl)\n",
    "* (c) TU Delft, 2023\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or `YOUR ANSWER HERE`. Remove `raise NotImplementedError()` afterwards. Moreover, if you see an empty cell, please DO NOT delete it, instead run that cell as you would run all other cells. Please fill in your name(s) and other required details below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9e220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please fill in your names, student numbers, netID, and emails below.\n",
    "STUDENT_1_NAME = \"\"\n",
    "STUDENT_1_STUDENT_NUMBER = \"\"\n",
    "STUDENT_1_NETID = \"\"\n",
    "STUDENT_1_EMAIL = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba32571",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "042927213b84aa368aa3ea72caa4cb60",
     "grade": true,
     "grade_id": "cell-9f148ec62e0de49c",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Note: this block is a check that you have filled in the above information.\n",
    "# It will throw an AssertionError until all fields are filled\n",
    "assert STUDENT_1_NAME != \"\"\n",
    "assert STUDENT_1_STUDENT_NUMBER != \"\"\n",
    "assert STUDENT_1_NETID != \"\"\n",
    "assert STUDENT_1_EMAIL != \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af317a94",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e76ef40fcc3f08a0484661497162a1a9",
     "grade": false,
     "grade_id": "cell-4ea391677951116c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### General announcements\n",
    "\n",
    "* Do *not* share your solutions, and do *not* copy solutions from others. By submitting your solutions, you claim that you alone are responsible for this code.\n",
    "\n",
    "* Do *not* email questions directly, since we want to provide everybody with the same information and avoid repeating the same answers. Instead, please post your questions regarding this assignment in the correct support forum on Brightspace, this way everybody can benefit from the response. If you do have a particular question that you want to ask directly, please use the scheduled Q&A hours to ask the TA.\n",
    "\n",
    "* There is a strict deadline for each assignment. Students are responsible to ensure that they have uploaded their work in time. So, please double check that your upload succeeded to the Brightspace and avoid any late penalties.\n",
    "\n",
    "* This [Jupyter notebook](https://jupyter.org/) uses `nbgrader` to help us with automated tests. `nbgrader` will make various cells in this notebook \"uneditable\" or \"unremovable\" and gives them a special id in the cell metadata. This way, when we run our checks, the system will check the existence of the cell ids and verify the number of points and which checks must be run. While there are ways that you can edit the metadata and work around the restrictions to delete or modify these special cells, you should not do that since then our nbgrader backend will not be able to parse your notebook and give you points for the assignment. You are free to add additional cells, but if you find a cell that you cannot modify or remove, please know that this is on purpose.\n",
    "\n",
    "* This notebook will have in various places a line that throws a `NotImplementedError` exception. These are locations where the assignment requires you to adapt the code! These lines are just there as a reminder for youthat you have not yet adapted that particular piece of code, especially when you execute all the cells. Once your solution code replaced these lines, it should accordingly *not* throw any exceptions anymore.\n",
    "\n",
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c956945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "387d2c60",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1caa31a593b03e8dd44f25386ce4c80f",
     "grade": false,
     "grade_id": "cell-ed88010142fb94bb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Task 2b - Using sensing for control (10p)\n",
    "\n",
    "**Author:** Maximilian St√∂lzle (M.W.Stolzle@tudelft.nl)\n",
    "\n",
    "The goal of this task is to use the CNN model trained in Task 1.4 to estimate the link angles and then use these estimated link angles $\\hat{\\theta} \\in \\mathbb{R}^2$ for closed-loop control of the robot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35339f62",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "28c46e0e7baef8e9191f9bf79140fb34",
     "grade": false,
     "grade_id": "cell-e33520fa3a4d3861",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Reloads the python files outside of this notebook automatically\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import all Python modules\n",
    "import cv2\n",
    "from distutils.util import strtobool\n",
    "from functools import partial\n",
    "from IPython.display import display, HTML  # For animations in the notebook\n",
    "from jax.config import config as jax_config\n",
    "\n",
    "jax_config.update(\"jax_platform_name\", \"cpu\")  # set default device to 'cpu'\n",
    "jax_config.update(\"jax_enable_x64\", True)  # double precision\n",
    "from jax import Array\n",
    "from jax import numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as onp\n",
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm.notebook import tqdm  # progress bar\n",
    "from typing import Callable, Dict, Tuple\n",
    "\n",
    "from jax_double_pendulum.analysis import *\n",
    "from jax_double_pendulum.dynamics import discrete_forward_dynamics, dynamical_matrices\n",
    "from jax_double_pendulum.kinematics import (\n",
    "    forward_kinematics,\n",
    "    extended_forward_kinematics,\n",
    ")\n",
    "from jax_double_pendulum.motion_planning import (\n",
    "    generate_ellipse_trajectory,\n",
    "    ELLIPSE_PARAMS,\n",
    ")\n",
    "from jax_double_pendulum.robot_parameters import ROBOT_PARAMS\n",
    "from jax_double_pendulum.robot_simulation import simulate_robot\n",
    "from jax_double_pendulum.utils import normalize_link_angles\n",
    "from jax_double_pendulum.visualization import animate_robot, render_robot_cv2\n",
    "\n",
    "# define boolean to check if the notebook is run for the purposes of autograding\n",
    "AUTOGRADING = strtobool(os.environ.get(\"AUTOGRADING\", \"false\"))\n",
    "\n",
    "# define folder where to save animations and plots\n",
    "outputs_dir = Path(\"outputs\")\n",
    "outputs_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253321a6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d0d6ab673c9dc60cfb959030f151cfed",
     "grade": false,
     "grade_id": "cell-90238ecbac1c4dd4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Implementing sensing into the simulation (0p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a055c9e4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8443c54bf8fb45fcc57f73f02c96fa90",
     "grade": false,
     "grade_id": "cell-108771f35c1422f7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Please implement a function to render the robot at a given configuration $\\theta$. **Hint:** make use of the following functions:\n",
    "\n",
    "- `forward_kinematics` in the `jax_double_pendulum.kinematics.forward_kinematics` module\n",
    "- `render_robot_cv2` in the `jax_double_pendulum.visualization.robot_rendering` module\n",
    "\n",
    "The image shall be of size $32 \\times 32$ pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c792fff5",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8ae10d4315588b71765d82119be4a0bf",
     "grade": false,
     "grade_id": "cell-f36a17d75e3893c4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def render_robot_configuration(rp: Dict, th: Array) -> onp.ndarray:\n",
    "    \"\"\"\n",
    "    Render robot configuration using OpenCV.\n",
    "    Args:\n",
    "        rp: robot parameters\n",
    "        th: link angles of shape (2, )\n",
    "    Returns:\n",
    "        img: rendered image of shape (32, 32, 3)\n",
    "    \"\"\"\n",
    "    img = onp.zeros((32, 32, 3))\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a9d20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose dummy link angles\n",
    "_th = jnp.array([jnp.pi / 4, -jnp.pi / 3])\n",
    "\n",
    "# render robot configuration as a BGR image\n",
    "_img = render_robot_configuration(ROBOT_PARAMS, _th)\n",
    "# transform image from BGR to RGB\n",
    "_img_rbg = cv2.cvtColor(_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# show image using Matplotlib\n",
    "# plt.axis(\"off\")\n",
    "plt.imshow(_img)\n",
    "plt.savefig(str(outputs_dir / \"task_2b_dummy_rendering.pdf\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9abf5d3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "709e6d68f5eb8d86bf585ec7f4129575",
     "grade": false,
     "grade_id": "cell-3d6e59d27f8b66ff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Next, please complete `sense_link_angles(.)`, which shall given a trained CNN and an image estimate the link angles $\\hat{\\theta}$. This implementation consists of the following steps:\n",
    "\n",
    "1. Transpose and reshape the image to the shape (batch, channels, height, width).\n",
    "2. Load the image from the numpy array into a `torch.Tensor` of type `float32`.\n",
    "3. Evaluate the CNN for the given torch image tensor and cast the output back into numpy.\n",
    "4. Assign the JAX array of shape (2, ) containing the link angles to the variable `th_est`. Remember that the neural network will output the sequence $[\\sin{\\hat{\\theta}_1}, \\sin{\\hat{\\theta}_2}, \\cos{\\hat{\\theta}_1}, \\cos{\\hat{\\theta}_2}] \\in \\mathbb{R}^4$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43463f33",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f6efc673ab436632dec8047f8af30fa3",
     "grade": false,
     "grade_id": "cell-eb403b6c173a76d0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def sense_link_angles(sensing_model: nn.Module, img: onp.ndarray) -> Array:\n",
    "    \"\"\"\n",
    "    Use trained CNN to sense link angles from rendered image.\n",
    "    Args:\n",
    "        sensing_model: PyTorch CNN model for sensing\n",
    "        img: image of robot of shape (32, 32, 3)\n",
    "    Returns:\n",
    "        th_est: estimated link angles of shape (2,)\n",
    "    \"\"\"\n",
    "    th_est = jnp.zeros((2,))\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    return th_est"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ba80d8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "206fc3b10f0796977527502dda6c0688",
     "grade": false,
     "grade_id": "cell-d9188f9d7f0536b1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now, we please load the saved neural network from Task 1.4 and activate the evaluation mode. **Please copy the (best-performing) model from the `assignment/problem_1/statedicts` to the `assignment/problem_2/statedicts` folder and specify the filename in the cell below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5e2b10",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a7460fa7a82e887737a092b47d795671",
     "grade": false,
     "grade_id": "cell-4f7be17f4b422352",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model_cnn_filename = \"xyz.pt\"\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# the model will be accessed in the directory `assignment/problem_2/statedicts`\n",
    "model_cnn_path = Path(\"statedicts\") / model_cnn_filename\n",
    "model_cnn = torch.jit.load(str(model_cnn_path))\n",
    "\n",
    "# Activate evaluation model\n",
    "model_cnn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daeeb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send dummy image through the model\n",
    "_th_est = sense_link_angles(model_cnn, _img)\n",
    "\n",
    "# comparing the estimated with the ground-truth link angles\n",
    "print(\"Ground-truth link angles:\", _th, \"rad\")\n",
    "print(\"Estimated link angles:\", _th_est, \"rad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9487a7ef",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "760e8e21323f60ad8e8bcf9f4ebb321b",
     "grade": false,
     "grade_id": "cell-a1cd751d44107412",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Please implement below the code executed at each time-step of the simulation. You can take inspiration from the `jax_double_pendulum/robot_simulation.py` file. Your implementation should contain the following steps:\n",
    "\n",
    "1. Evaluate the feed-forward and the feedback controllers `ctrl_ff` and `ctrl_fb` at the _estimated_ link angles `th_est`. **Please note that if you evaluate the controllers at the _actual_ link angles `th` instead, you will receive zero points for this task.**\n",
    "2. Then, call the `discrete_forward_dynamics_fn` on the _actual_ system state to receive the system state at the next time step.\n",
    "3. Next, render an image of the robot at the next time step.\n",
    "4. Use that image to estimate the link angles at the next time-step using the CNN and save the result in the `th_next_est` variable.\n",
    "5. Finally, compute the forward kinematics at the next estimated link angles `th_next_est` and save the elbow and end-effector positions into the variables `x_eb_next_est` and `x_next_est`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70c356c",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d91dd36a7955d47f891a53ae5ac0bf4b",
     "grade": false,
     "grade_id": "cell-f7a9792d1f6f7d35",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def simulation_with_sensing_iteration(\n",
    "    rp: Dict,\n",
    "    dt: Array,\n",
    "    sensing_model: nn.Module,\n",
    "    discrete_forward_dynamics_fn: Callable,\n",
    "    th: Array,\n",
    "    th_est: Array,\n",
    "    th_d: Array,\n",
    "    tau_ext: Array,\n",
    "    th_des: Array,\n",
    "    th_d_des: Array,\n",
    "    th_dd_des: Array,\n",
    "    ctrl_ff: Callable,\n",
    "    ctrl_fb: Callable,\n",
    ") -> Tuple[\n",
    "    Array,\n",
    "    Array,\n",
    "    Array,\n",
    "    Array,\n",
    "    Array,\n",
    "    Array,\n",
    "    Array,\n",
    "    Array,\n",
    "    Array,\n",
    "    Array,\n",
    "    Array,\n",
    "    Array,\n",
    "    Array,\n",
    "]:\n",
    "    \"\"\"\n",
    "    Simulates the double pendulum robot for one time step while integrating sensing using a trained CNN\n",
    "    Args:\n",
    "        rp: dictionary of robot parameters\n",
    "        dt: time step between the current and the next state [s]\n",
    "        sensing_model: PyTorch CNN model for sensing\n",
    "        discrete_forward_dynamics_fn: function that computes the discrete forward dynamics.\n",
    "            Given the time step dt, the current link state (th, th_d), and the link torque tau,\n",
    "            it needs to return the next link state (th, th_d) and the link angular acceleration th_dd.\n",
    "            It must have the signature: discrete_forward_dynamics_fn(dt, th, th_d, tau) -> (th_next, th_d_next, th_dd)\n",
    "        th: ground-truth link angles of shape (2, )\n",
    "        th_est: estimated link angles of shape (2, )\n",
    "        th_d: ground-truth link angular velocities of shape (2, )\n",
    "        tau_ext: link torques of shape (2, )\n",
    "            which are applied to the system in addition to the evaluated feedforward and feedback torques\n",
    "        th_des: desired link angles of shape (2, )\n",
    "        th_d_des: desired link angular velocities of shape (2, )\n",
    "        th_dd_des: desired link angular accelerations of shape (2, )\n",
    "        ctrl_ff: callable computing the feed-forward control torques. Needs to return jax.array of shape (2, )\n",
    "            It must have the signature: ctrl_ff(th, th_d, th_des, th_d_des, th_dd_des) -> tau_ff\n",
    "        ctrl_fb: callable computing the feed-back control torques. Needs to return jax.array of shape (2, )\n",
    "            It must have the signature: ctrl_fb(th, th_d, th_des, th_d_des) -> tau_fb\n",
    "\n",
    "    Returns:\n",
    "        th_next: next link angles of shape (2, )\n",
    "        th_next_est: next estimated link angles of shape (2, )\n",
    "        th_d_next: next link angular velocities of shape (2, )\n",
    "        th_dd: link angular accelerations of shape (2, )\n",
    "        x_next: next end-effector position of shape (2, )\n",
    "        x_next_est: next estimated end-effector position of shape (2, )\n",
    "        x_d_next: next end-effector velocity of shape (2, )\n",
    "        x_dd: end-effector acceleration of shape (2, )\n",
    "        x_eb_next: next position of elbow joint of shape (2, )\n",
    "        x_eb_next_est: next estimated position of elbow joint of shape (2, )\n",
    "        tau: total external torque applied to the links of shape (2, )\n",
    "        tau_ff: torque computed by feed-forward controller of shape (2, )\n",
    "        tau_fb: torque computed by feedback controller of shape (2, )\n",
    "    \"\"\"\n",
    "    # evaluate feedforward and feedback controllers at the estimated link angles\n",
    "    # Hint: check the implementation in `jax_double_pendulum.robot_simulation`\n",
    "    tau_ff = jnp.zeros_like(tau_ext)\n",
    "    tau_fb = jnp.zeros_like(tau_ext)\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    tau = tau_ext + tau_ff + tau_fb\n",
    "\n",
    "    # evaluate the dynamics at the ground-truth state\n",
    "    th_next = jnp.zeros_like(th)\n",
    "    th_d_next = jnp.zeros_like(th_d)\n",
    "    th_dd = jnp.zeros_like(th)\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    # evaluate forward kinematics at the ground-truth state of the next time-step\n",
    "    x_next, x_d_next, x_dd, x_eb_next = extended_forward_kinematics(\n",
    "        rp, th_next, th_d_next, th_dd\n",
    "    )\n",
    "\n",
    "    # render robot configuration for the next ground-truth link angles\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    # estimate the next link angles from the rendered image\n",
    "    th_next_est = jnp.zeros_like(th_next)\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    # make sure that the estimated link angles are in the range [-pi, pi]\n",
    "    th_next_est = th_est + normalize_link_angles(th_next_est - th_est)\n",
    "\n",
    "    # evaluate forward kinematics for the next estimated link angles\n",
    "    # i.e. estimate the next elbow joint position `x_eb_next_est`,\n",
    "    # and the next end-effector position `x_next_est`\n",
    "    x_eb_next_est, x_next_est = jnp.zeros_like(x_eb_next), jnp.zeros_like(x_next)\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    return (\n",
    "        th_next,\n",
    "        th_next_est,\n",
    "        th_d_next,\n",
    "        th_dd,\n",
    "        x_next,\n",
    "        x_next_est,\n",
    "        x_d_next,\n",
    "        x_dd,\n",
    "        x_eb_next,\n",
    "        x_eb_next_est,\n",
    "        tau,\n",
    "        tau_ff,\n",
    "        tau_fb,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc8990a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e4a5b470f7b6bad6c26f96db65c52fca",
     "grade": false,
     "grade_id": "cell-aa932227756b5796",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Finally, we design the simulation loop. Please implement the the estimation of the link angles for the first time-step with index 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa8c944",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f64896884ef3057ebc02bff2c599a24b",
     "grade": false,
     "grade_id": "cell-92e13ecbe7989f38",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def simulate_robot_with_sensing(\n",
    "    rp: dict,\n",
    "    t_ts: jnp.ndarray,\n",
    "    sensing_model: nn.Module,\n",
    "    discrete_forward_dynamics_fn: Callable = None,\n",
    "    th_0: jnp.ndarray = jnp.array([0.0, 0.0]),\n",
    "    th_d_0: jnp.ndarray = jnp.array([0.0, 0.0]),\n",
    "    tau_ext_ts: jnp.ndarray = None,\n",
    "    th_des_ts: jnp.ndarray = None,\n",
    "    th_d_des_ts: jnp.ndarray = None,\n",
    "    th_dd_des_ts: jnp.ndarray = None,\n",
    "    ctrl_ff: Callable = lambda th, th_d, th_des, th_d_des, th_dd_des: jnp.zeros((2,)),\n",
    "    ctrl_fb: Callable = lambda th, th_d, th_des, th_d_des: jnp.zeros((2,)),\n",
    ") -> Dict[str, jnp.ndarray]:\n",
    "    \"\"\"\n",
    "    Simulates the double pendulum robot with sensing.\n",
    "\n",
    "    Args:\n",
    "        rp: dictionary of robot parameters\n",
    "        t_ts: time steps of the trajectory [s] of shape (num_time_steps, )\n",
    "        sensing_model: PyTorch CNN model for sensing\n",
    "        discrete_forward_dynamics_fn: function that computes the discrete forward dynamics.\n",
    "            Given the time step dt, the current link state (th, th_d), and the link torque tau,\n",
    "            it needs to return the next link state (th, th_d) and the link angular acceleration th_dd.\n",
    "            It must have the signature: discrete_forward_dynamics_fn(dt, th, th_d, tau) -> (th_next, th_d_next, th_dd)\n",
    "        th_0: initial link angles of shape (2, )\n",
    "        th_d_0: initial link angular velocities of shape (2, )\n",
    "        tau_ext_ts: link torques of shape (num_time_steps, 2)\n",
    "            which are applied to the system in addition to the evaluated feedforward and feedback torques\n",
    "        th_des_ts: desired link angles of shape (num_time_steps, 2)\n",
    "        th_d_des_ts: desired link angular velocities of shape (num_time_steps, 2)\n",
    "        th_dd_des_ts: desired link angular accelerations of shape (num_time_steps, 2)\n",
    "        ctrl_ff: callable computing the feed-forward control torques. Needs to return jax.array of shape (2, )\n",
    "            It must have the signature: ctrl_ff(th, th_d, th_des, th_d_des, th_dd_des) -> tau_ff\n",
    "        ctrl_fb: callable computing the feed-back control torques. Needs to return jax.array of shape (2, )\n",
    "            It must have the signature: ctrl_fb(th, th_d, th_des, th_d_des) -> tau_fb\n",
    "\n",
    "    Returns:\n",
    "        sim_ts: dictionary of states and other time series data of simulation\n",
    "    \"\"\"\n",
    "    if discrete_forward_dynamics_fn is None:\n",
    "        discrete_forward_dynamics_fn = partial(discrete_forward_dynamics, rp)\n",
    "\n",
    "    if tau_ext_ts is None:\n",
    "        tau_ext_ts = jnp.zeros((t_ts.shape[0], 2))\n",
    "\n",
    "    if th_des_ts is None:\n",
    "        th_des_ts = jnp.zeros((t_ts.shape[0], 2))\n",
    "\n",
    "    if th_d_des_ts is None:\n",
    "        th_d_des_ts = jnp.zeros((t_ts.shape[0], 2))\n",
    "\n",
    "    if th_dd_des_ts is None:\n",
    "        th_dd_des_ts = jnp.zeros((t_ts.shape[0], 2))\n",
    "\n",
    "    num_time_steps = t_ts.shape[0]\n",
    "\n",
    "    # initialize diagnostic dictionary of system states over the trajectory\n",
    "    sim_ts = dict(\n",
    "        t_ts=t_ts,\n",
    "        th_ts=jnp.zeros((num_time_steps, 2)),\n",
    "        th_est_ts=jnp.zeros((num_time_steps, 2)),\n",
    "        th_d_ts=jnp.zeros((num_time_steps, 2)),\n",
    "        th_dd_ts=jnp.zeros((num_time_steps, 2)),\n",
    "        x_ts=jnp.zeros((num_time_steps, 2)),\n",
    "        x_est_ts=jnp.zeros((num_time_steps, 2)),\n",
    "        x_d_ts=jnp.zeros((num_time_steps, 2)),\n",
    "        x_dd_ts=jnp.zeros((num_time_steps, 2)),\n",
    "        x_eb_ts=jnp.zeros((num_time_steps, 2)),\n",
    "        x_eb_est_ts=jnp.zeros((num_time_steps, 2)),\n",
    "        tau_ts=jnp.zeros((num_time_steps, 2)),\n",
    "        tau_ff_ts=jnp.zeros((num_time_steps, 2)),\n",
    "        tau_fb_ts=jnp.zeros((num_time_steps, 2)),\n",
    "    )\n",
    "\n",
    "    # evaluate quantities at initial state\n",
    "    sim_ts[\"th_ts\"] = sim_ts[\"th_ts\"].at[0].set(th_0)\n",
    "    sim_ts[\"th_d_ts\"] = sim_ts[\"th_d_ts\"].at[0].set(th_d_0)\n",
    "    x_0, x_d_0, x_dd_0, x_eb_0 = extended_forward_kinematics(\n",
    "        rp, th_0, th_d_0, th_dd=jnp.zeros((2,))\n",
    "    )\n",
    "    sim_ts[\"x_ts\"] = sim_ts[\"x_ts\"].at[0].set(x_0)\n",
    "    sim_ts[\"x_d_ts\"] = sim_ts[\"x_d_ts\"].at[0].set(x_d_0)\n",
    "    sim_ts[\"x_dd_ts\"] = sim_ts[\"x_dd_ts\"].at[0].set(x_dd_0)\n",
    "    sim_ts[\"x_eb_ts\"] = sim_ts[\"x_eb_ts\"].at[0].set(x_eb_0)\n",
    "\n",
    "    # estimate link angles, elbow and end-effector positions at the initial state\n",
    "    th_est_0 = jnp.zeros_like(th_0)\n",
    "    x_eb_est_0 = jnp.zeros_like(x_0)\n",
    "    x_est_0 = jnp.zeros_like(x_eb_0)\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    sim_ts[\"th_est_ts\"] = sim_ts[\"th_est_ts\"].at[0].set(th_est_0)\n",
    "    sim_ts[\"x_eb_est_ts\"] = sim_ts[\"x_eb_est_ts\"].at[0].set(x_eb_est_0)\n",
    "    sim_ts[\"x_est_ts\"] = sim_ts[\"x_est_ts\"].at[0].set(x_est_0)\n",
    "\n",
    "    for time_idx in (pbar := tqdm(range(1, num_time_steps))):\n",
    "        dt = t_ts[time_idx] - t_ts[time_idx - 1]\n",
    "        (\n",
    "            th,\n",
    "            th_est,\n",
    "            th_d,\n",
    "            th_dd,\n",
    "            x,\n",
    "            x_est,\n",
    "            x_d,\n",
    "            x_dd,\n",
    "            x_eb,\n",
    "            x_eb_est,\n",
    "            tau,\n",
    "            tau_ff,\n",
    "            tau_fb,\n",
    "        ) = simulation_with_sensing_iteration(\n",
    "            rp,\n",
    "            dt,\n",
    "            sensing_model,\n",
    "            discrete_forward_dynamics_fn,\n",
    "            sim_ts[\"th_ts\"][time_idx - 1],\n",
    "            sim_ts[\"th_est_ts\"][time_idx - 1],\n",
    "            sim_ts[\"th_d_ts\"][time_idx - 1],\n",
    "            tau_ext_ts[time_idx - 1],\n",
    "            th_des_ts[time_idx],\n",
    "            th_d_des_ts[time_idx],\n",
    "            th_dd_des_ts[time_idx],\n",
    "            ctrl_ff,\n",
    "            ctrl_fb,\n",
    "        )\n",
    "        sim_ts[\"th_ts\"] = sim_ts[\"th_ts\"].at[time_idx].set(th)\n",
    "        sim_ts[\"th_est_ts\"] = sim_ts[\"th_est_ts\"].at[time_idx].set(th_est)\n",
    "        sim_ts[\"th_d_ts\"] = sim_ts[\"th_d_ts\"].at[time_idx].set(th_d)\n",
    "        sim_ts[\"th_dd_ts\"] = sim_ts[\"th_dd_ts\"].at[time_idx].set(th_dd)\n",
    "        sim_ts[\"x_ts\"] = sim_ts[\"x_ts\"].at[time_idx].set(x)\n",
    "        sim_ts[\"x_est_ts\"] = sim_ts[\"x_est_ts\"].at[time_idx].set(x_est)\n",
    "        sim_ts[\"x_d_ts\"] = sim_ts[\"x_d_ts\"].at[time_idx].set(x_d)\n",
    "        sim_ts[\"x_dd_ts\"] = sim_ts[\"x_dd_ts\"].at[time_idx].set(x_dd)\n",
    "        sim_ts[\"x_eb_ts\"] = sim_ts[\"x_eb_ts\"].at[time_idx].set(x_eb)\n",
    "        sim_ts[\"x_eb_est_ts\"] = sim_ts[\"x_eb_est_ts\"].at[time_idx].set(x_eb_est)\n",
    "        sim_ts[\"tau_ts\"] = sim_ts[\"tau_ts\"].at[time_idx - 1].set(tau)\n",
    "        sim_ts[\"tau_ff_ts\"] = sim_ts[\"tau_ff_ts\"].at[time_idx - 1].set(tau_ff)\n",
    "        sim_ts[\"tau_fb_ts\"] = sim_ts[\"tau_fb_ts\"].at[time_idx - 1].set(tau_fb)\n",
    "\n",
    "    return sim_ts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae56f654",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "29262620c0a8750f82b945161f2e4431",
     "grade": false,
     "grade_id": "cell-fe12b8de9b7c8711",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Simulating the closed-loop system (10p)\n",
    "\n",
    "Please simulate the closed-loop system using the PD + feedforward controller from task 2a.3 for regulating the system to follow the given ellipse trajectory. However, now the controller (both feed-forward and feedback) will use the estimated link angles instead of the actual ones. You are free to tune the feedback gains of the PD controller yourself to achieve the best possible performance for your trained sensing CNN.\n",
    "\n",
    "You will receive 2 points for your implementation (i.e. if your code runs through without any errors). The remaining 8 points are attributed based on the performance of your closed-loop control system. You will receive the full 8 performance points if the Euclidean norm of the RMSE of the end-effector position between the reference trajectory and the actual (i.e. not estimated) robot evolution is **below** 0.5 m. If the error is between 0.5 m and 1.5 m, your grade will be linarly scaled with the error. However, if the error is larger than 1.5 m, you will not receive any credits for the control performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e71a9c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "89b46e19585882ea022bf66982cdb854",
     "grade": false,
     "grade_id": "cell-5dcd52f754d55bd1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# simulation parameters\n",
    "sim_duration = 5.0  # [s]\n",
    "sim_dt = 1e-2  # [s]\n",
    "\n",
    "# define time steps\n",
    "t_ts = sim_dt * jnp.arange(int(sim_duration / sim_dt))\n",
    "\n",
    "# generate trajectory\n",
    "traj_ts = generate_ellipse_trajectory(\n",
    "    rp=ROBOT_PARAMS,\n",
    "    t_ts=t_ts,\n",
    "    **ELLIPSE_PARAMS,\n",
    ")\n",
    "\n",
    "# initial link angles (i.e. at the first time-step)\n",
    "th_0 = traj_ts[\"th_ts\"][0] - jnp.array([0.1, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bef4f6",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f47bd163adaac548b53b6a2def79ab1d",
     "grade": false,
     "grade_id": "cell-8210b22e8d95b3b62",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# import PD feedback and PD + feedforward controllers from controllers.ipynb\n",
    "from ipynb.fs.full.controllers import ctrl_fb_pd, ctrl_ff_feedforward\n",
    "\n",
    "# construct feedforward controller\n",
    "ctrl_ff = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# controller parameters\n",
    "# define the proportional gain matrix kp and the derivative gain matrix kd\n",
    "kp = 500 * jnp.eye(2)  # [Nm/rad]\n",
    "kd = 50 * jnp.eye(2)  # [Nm s/rad]\n",
    "\n",
    "# simulate the robot with the given controller\n",
    "# save the simulation date in `sim_ts`\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# evaluate the control performance quantitatively\n",
    "rmse_th, rmse_th_d, rmse_th_dd = compute_configuration_space_rmse(traj_ts, sim_ts)\n",
    "rmse_x, rmse_x_d, rmse_x_dd = compute_operational_space_rmse(traj_ts, sim_ts)\n",
    "with jnp.printoptions(precision=3):\n",
    "    print(\n",
    "        \"RMSE theta:\",\n",
    "        rmse_th,\n",
    "        \"rad, RMSE theta_d:\",\n",
    "        rmse_th_d,\n",
    "        \"rad/s, RMSE theta_dd:\",\n",
    "        rmse_th_dd,\n",
    "        \"rad/s^2\",\n",
    "    )\n",
    "    print(\n",
    "        \"RMSE x:\",\n",
    "        f\"{jnp.linalg.norm(rmse_x):.4f}\",\n",
    "        \"m, RMSE x_d:\",\n",
    "        f\"{jnp.linalg.norm(rmse_x_d):.3f}\",\n",
    "        \"m/s, RMSE x_dd:\",\n",
    "        f\"{jnp.linalg.norm(rmse_x_dd):.2f}\",\n",
    "        \"m/s^2\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b60b272",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3bcef219984e147ea588cb4e9cf42f45",
     "grade": true,
     "grade_id": "cell-5ee027e748985949",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT REMOVE OR MODIFY THIS CELL\n",
    "\n",
    "rmse_th, rmse_th_d, rmse_th_dd = compute_configuration_space_rmse(traj_ts, sim_ts)\n",
    "rmse_x, rmse_x_d, rmse_x_dd = compute_operational_space_rmse(traj_ts, sim_ts)\n",
    "\n",
    "grader_max_impl_points = 2  # points for a correct implementation\n",
    "grader_max_perf_points = 8  # points for a good control performance\n",
    "\n",
    "rmse_x_norm = jnp.linalg.norm(rmse_x)  # achieved RMSE in operational space\n",
    "rmse_x_lb = 0.5  # m --> this will result in the full grade for the control performance\n",
    "rmse_x_ub = 1.5  # m --> this will result in zero points for the control performance\n",
    "\n",
    "grader_perf_points = grader_max_perf_points * (\n",
    "    (1 - (rmse_x_norm - rmse_x_lb) / (rmse_x_ub - rmse_x_lb))\n",
    ")\n",
    "grader_perf_points = jnp.clip(grader_perf_points, 0, grader_max_perf_points).item()\n",
    "\n",
    "grader_points = grader_max_impl_points + grader_perf_points\n",
    "\n",
    "print(\n",
    "    f\"If you submit the assignment as it is, you will receive {grader_points} points.\"\n",
    ")\n",
    "\n",
    "\n",
    "grader_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d672e713",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f095ef9b87e4c8b52c46b110f92a3603",
     "grade": false,
     "grade_id": "cell-7aacd2a5dfff0085",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# plot the configuration-space evolution\n",
    "plot_configuration_space_trajectory_following(\n",
    "    traj_ts,\n",
    "    sim_ts,\n",
    "    filepath=str(outputs_dir / \"task_2b_configuration_space_trajectory_following.pdf\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e13585",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d1e8d9fc6e68d11976c4ab2f72ef2691",
     "grade": false,
     "grade_id": "cell-59523b8231c27db0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# plot the operational-space evolution\n",
    "plot_operational_space_trajectory_following(\n",
    "    traj_ts,\n",
    "    sim_ts,\n",
    "    filepath=str(outputs_dir / \"task_2b_operational_space_trajectory_following.pdf\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef0a906",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8924bb7879737e682487681d1f530ca8",
     "grade": false,
     "grade_id": "cell-3414576f6ff34f97",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# plot the actuation sequence\n",
    "plot_actuation(sim_ts, filepath=str(outputs_dir / \"task_2b_actuation.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9b3c7a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "620d0105c97a19ecac36b528627b98d3",
     "grade": false,
     "grade_id": "cell-14798fd8a1c2f5e8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "if not AUTOGRADING:\n",
    "    sim_hat_ts = {\n",
    "        \"x_ts\": sim_ts[\"x_est_ts\"],\n",
    "        \"x_eb_ts\": sim_ts[\"x_eb_est_ts\"],\n",
    "    }\n",
    "    ani = animate_robot(\n",
    "        ROBOT_PARAMS,\n",
    "        traj_ts=traj_ts,\n",
    "        sim_ts=sim_ts,\n",
    "        sim_hat_ts=sim_hat_ts,\n",
    "        step_skip=5,\n",
    "        show=False,\n",
    "        filepath=str(outputs_dir / \"task_2b_controlled_robot.mp4\"),\n",
    "    )\n",
    "    display(HTML(ani.to_html5_video()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16178e33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "3c33fd8c47bb8dc89529054a21fe93e59b583c34f2f889eef9ace7a4e9cf402f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
