{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac408b5e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a96d02d6346fa7399cf6da0111ce0937",
     "grade": false,
     "grade_id": "cell-b00828259c8e42e8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# RO47019: Intelligent Control Systems Practical Assignment\n",
    "* Period: 2022-2023, Q3\n",
    "* Course homepage: https://brightspace.tudelft.nl/d2l/home/500969\n",
    "* Instructor: Cosimo Della Santina (C.DellaSantina@tudelft.nl)\n",
    "* Teaching assistant: Ruben Martin Rodriguez (R.MartinRodriguez@student.tudelft.nl)\n",
    "* (c) TU Delft, 2023\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or `YOUR ANSWER HERE`. Remove `raise NotImplementedError()` afterwards. Moreover, if you see an empty cell, please DO NOT delete it, instead run that cell as you would run all other cells. Please fill in your name(s) and other required details below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9e220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please fill in your names, student numbers, netID, and emails below.\n",
    "STUDENT_1_NAME = \"\"\n",
    "STUDENT_1_STUDENT_NUMBER = \"\"\n",
    "STUDENT_1_NETID = \"\"\n",
    "STUDENT_1_EMAIL = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba32571",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "042927213b84aa368aa3ea72caa4cb60",
     "grade": true,
     "grade_id": "cell-9f148ec62e0de49c",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Note: this block is a check that you have filled in the above information.\n",
    "# It will throw an AssertionError until all fields are filled\n",
    "assert STUDENT_1_NAME != \"\"\n",
    "assert STUDENT_1_STUDENT_NUMBER != \"\"\n",
    "assert STUDENT_1_NETID != \"\"\n",
    "assert STUDENT_1_EMAIL != \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af317a94",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e76ef40fcc3f08a0484661497162a1a9",
     "grade": false,
     "grade_id": "cell-4ea391677951116c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### General announcements\n",
    "\n",
    "* Do *not* share your solutions, and do *not* copy solutions from others. By submitting your solutions, you claim that you alone are responsible for this code.\n",
    "\n",
    "* Do *not* email questions directly, since we want to provide everybody with the same information and avoid repeating the same answers. Instead, please post your questions regarding this assignment in the correct support forum on Brightspace, this way everybody can benefit from the response. If you do have a particular question that you want to ask directly, please use the scheduled Q&A hours to ask the TA.\n",
    "\n",
    "* There is a strict deadline for each assignment. Students are responsible to ensure that they have uploaded their work in time. So, please double check that your upload succeeded to the Brightspace and avoid any late penalties.\n",
    "\n",
    "* This [Jupyter notebook](https://jupyter.org/) uses `nbgrader` to help us with automated tests. `nbgrader` will make various cells in this notebook \"uneditable\" or \"unremovable\" and gives them a special id in the cell metadata. This way, when we run our checks, the system will check the existence of the cell ids and verify the number of points and which checks must be run. While there are ways that you can edit the metadata and work around the restrictions to delete or modify these special cells, you should not do that since then our nbgrader backend will not be able to parse your notebook and give you points for the assignment. You are free to add additional cells, but if you find a cell that you cannot modify or remove, please know that this is on purpose.\n",
    "\n",
    "* This notebook will have in various places a line that throws a `NotImplementedError` exception. These are locations where the assignment requires you to adapt the code! These lines are just there as a reminder for youthat you have not yet adapted that particular piece of code, especially when you execute all the cells. Once your solution code replaced these lines, it should accordingly *not* throw any exceptions anymore.\n",
    "\n",
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c956945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a82fa904",
   "metadata": {},
   "source": [
    "# Task 1.0 - Generate the datasets (0p)\n",
    "\n",
    "**Authors:** Tom√°s Coleman (T.Coleman@tudelft.nl), Chuhan Zhang (C.Zhang-8@tudelft.nl)\n",
    "\n",
    "### NOTE: This notebook is a replacement for the CNN-part in `task_1a_generate_data.ipynb`\n",
    "\n",
    "Due to the memory limitation of GitHub Codespaces, we recommend using this notebook instead to generate the **CNN** data. The procedure of generating data is exactly the same as the original notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8009783a",
   "metadata": {},
   "source": [
    "### Training data for tasks 1.1-1.4\n",
    "\n",
    "In order to train the model, we require data. Therefore, we generate images of the robot at various positions in its state space. \n",
    "At every position chosen in the state space, an RGB image with dimensions 32x32x3, is generated as observation data $x$ together with the corresponding robot state $s=(\\theta, \\dot{\\theta})$, where $\\theta = [\\theta_1, \\theta_2]$ are the link angles of the robot, and $\\dot{\\theta} = [\\dot{\\theta_1}, \\dot{\\theta_2}]$ are the link angular velocities of the robot. \n",
    "The angle $\\theta_1$ of link 1 and $\\theta_2$ of link 2 are both defined with respect to the right horizontal position (or x-axis), both are wrapped to the $[-\\pi, \\pi]$ domain. \n",
    "\n",
    "We also generate a test set, which are observations of the robot sampled at every $2^{\\circ}$, of the first link and at every $2^{\\circ}$ of the second link for every sample of the first, giving 32400 (180x180) observations. \n",
    "\n",
    "Run the cells below to generate the data needed for the problems in `task_1b_train_NN.ipynb`.\n",
    "\n",
    "**This notebook is not graded but is required for all tasks of problem 1.**\n",
    "\n",
    "**Please do __not__ include the datasets of Problem 1 in your final submission!** I.e. exclude the `source/problem_1/datasets` folder from your ZIP archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae8f323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reloads the python files outside of this notebook automatically\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import all Python modules\n",
    "from distutils.util import strtobool\n",
    "from jax.config import config as jax_config\n",
    "\n",
    "jax_config.update(\"jax_platform_name\", \"cpu\")  # set default device to 'cpu'\n",
    "jax_config.update(\"jax_enable_x64\", True)  # double precision\n",
    "from jax import jit, lax, random\n",
    "from jax import numpy as jnp\n",
    "import numpy as onp\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "import shutil\n",
    "import torch\n",
    "\n",
    "from jax_double_pendulum.robot_parameters import ROBOT_PARAMS\n",
    "from jax_double_pendulum.kinematics import forward_kinematics\n",
    "from utils import *\n",
    "\n",
    "\n",
    "# define boolean to check if the notebook is run for the purposes of autograding\n",
    "AUTOGRADING = strtobool(os.environ.get(\"AUTOGRADING\", \"false\"))\n",
    "\n",
    "# folder to save the dataset to\n",
    "datasets_folder = Path(\"datasets\")\n",
    "datasets_folder.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# create directory for plots\n",
    "outputs_dir = Path(\"outputs\")\n",
    "outputs_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0da00c",
   "metadata": {},
   "source": [
    "## Generating dataset of state images \n",
    "\n",
    "### Training data for tasks 1.1-1.4\n",
    "\n",
    "In order to train the model, we require data. Therefore, we generate images of the robot at various positions in its state space. \n",
    "At every position chosen in the state space, an RGB image with dimensions 32x32x3, is generated as observation data $x$ together with the corresponding robot state $s=(\\theta, \\dot{\\theta})$, where $\\theta = [\\theta_1, \\theta_2]$ are the link angles of the robot, and $\\dot{\\theta} = [\\dot{\\theta_1}, \\dot{\\theta_2}]$ are the link angular velocities of the robot. \n",
    "The angle $\\theta_1$ of link 1 and $\\theta_2$ of link 2 are both defined with respect to the right horizontal position (or x-axis), both are wrapped to the $[-\\pi, \\pi]$ domain. \n",
    "\n",
    "#### Training data\n",
    "\n",
    "The training data constists of 20,000 images of the robot with link angles that are randomly sampled from the state space. \n",
    "- The link angles are first sampled and saved into the dataset with the label `th_curr_ss` to be used later as the ground truth labels. \n",
    "- From these angles, the robot is rendered into the 32x32x3 RGB images. Link 1 is blue and link 2 is red.\n",
    "\n",
    "#### Test data\n",
    "We also generate a test set, which are again 32x32x3 image observations of the robot sampled at every $2^{\\circ}$, of the first link and at every $2^{\\circ}$ of the second link for every sample of the first, giving 32400 (180x180) observations. Having a test data set larger than the training set is unusual in practice as we want our model to have as much data to train on in practice. As this is a training excercise (for you and the neural networks :), we generate this large test set over the state space so you can fully analyse the performance of the trained Neural Networks.\n",
    "\n",
    "Run the cells below to generate the data needed for the problems in `task_1b_train_NN.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1bcb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def save_test_data_to_dataset(\n",
    "    _dataset: Dict[str, jnp.ndarray],\n",
    "    initial_conditions: jnp.array,\n",
    ") -> Dict[str, jnp.ndarray]:\n",
    "    \"\"\"\n",
    "    puts the robot angle and x-y joint position in the dataset\n",
    "    \"\"\"\n",
    "    num_ic = initial_conditions.shape[0]\n",
    "    _dataset[\"th_curr_ss\"] = _dataset[\"th_curr_ss\"].at[:].set(initial_conditions)\n",
    "\n",
    "    # Gets the robot elbow and end effector x-y coordinates from the 'forward_kinematics' function\n",
    "    def _for_loop_cart_fun(idx, _dataset: Dict):\n",
    "        _x_eb, _x = forward_kinematics(ROBOT_PARAMS, _dataset[\"th_curr_ss\"][idx])\n",
    "        _dataset[\"x_eb_ts\"] = _dataset[\"x_eb_ts\"].at[idx].set(_x_eb)\n",
    "        _dataset[\"x_ts\"] = _dataset[\"x_ts\"].at[idx].set(_x)\n",
    "        return _dataset\n",
    "\n",
    "    _dataset = lax.fori_loop(\n",
    "        lower=0, upper=num_ic, body_fun=_for_loop_cart_fun, init_val=_dataset\n",
    "    )\n",
    "\n",
    "    return _dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4aebfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image_data_to_dataset(\n",
    "    _dataset: Dict[str, jnp.ndarray], ROBOT_PARAMS: Dict[str, jnp.ndarray]\n",
    ") -> Dict[str, jnp.ndarray]:\n",
    "    \"\"\"\n",
    "    This function calls the 'draw_robot' function to draw the image\n",
    "    of the robot at each given theta values and returns the given\n",
    "    dataset with these drawn images corresponding to given angles\n",
    "    \"\"\"\n",
    "    _dataset = draw_robot(_dataset, ROBOT_PARAMS)\n",
    "\n",
    "    return _dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f66af7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed so everyone has the same \"random\" training dataset\n",
    "onp.random.seed(42)\n",
    "\n",
    "# simulation parameters\n",
    "num_samples_train = 20000\n",
    "img_size = 32\n",
    "\n",
    "# Sample the state space of -pi to pi for both robot links\n",
    "training_angles_sampled = onp.random.uniform(-onp.pi, onp.pi, [num_samples_train, 2])\n",
    "\n",
    "# Generate test data: 40 x 40 images to evenly cover the state space\n",
    "th1_range = jnp.arange(-jnp.pi, jnp.pi, jnp.pi / 45.0)\n",
    "th2_range = jnp.arange(-jnp.pi, jnp.pi, jnp.pi / 45.0)\n",
    "\n",
    "test_angles = jnp.array(jnp.meshgrid(th1_range, th2_range)).T.reshape(-1, 2)\n",
    "\n",
    "num_samples_test = len(th1_range) * len(th2_range)\n",
    "\n",
    "# initialise the train and test datasets with the appropriate sized arrays\n",
    "# for the link angles \"th_curr_ss\", x-y elbow position \"x_eb_ts\",\n",
    "# x-y end effector position \"x_ts\" and the rendered image of the\n",
    "# robot at \"th_curr_ss\"\n",
    "training_dataset = {\n",
    "    \"th_curr_ss\": jnp.zeros((num_samples_train, 2)),\n",
    "    \"x_eb_ts\": jnp.zeros((num_samples_train, 2)),\n",
    "    \"x_ts\": jnp.zeros((num_samples_train, 2)),\n",
    "    \"th_pix_curr\": jnp.zeros(\n",
    "        (num_samples_train, img_size, img_size, 3), dtype=jnp.uint8\n",
    "    ),\n",
    "}\n",
    "\n",
    "test_dataset = {\n",
    "    \"th_curr_ss\": jnp.zeros((num_samples_test, 2)),\n",
    "    \"x_eb_ts\": jnp.zeros((num_samples_test, 2)),\n",
    "    \"x_ts\": jnp.zeros((num_samples_test, 2)),\n",
    "    \"th_pix_curr\": jnp.zeros(\n",
    "        (num_samples_test, img_size, img_size, 3), dtype=jnp.uint8\n",
    "    ),\n",
    "}\n",
    "\n",
    "# input the initial values in the dataset\n",
    "training_dataset = save_test_data_to_dataset(training_dataset, training_angles_sampled)\n",
    "test_dataset = save_test_data_to_dataset(test_dataset, test_angles)\n",
    "\n",
    "print(\"Rendering images of the robot for the training set ...\")\n",
    "training_dataset = save_image_data_to_dataset(training_dataset, ROBOT_PARAMS)\n",
    "\n",
    "print(\"Rendering images of the robot for the test set ...\")\n",
    "test_dataset = save_image_data_to_dataset(test_dataset, ROBOT_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6979d8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now save the dataset to a file so we can access it in the notebook for tasks 1.1-1.4\n",
    "jnp.savez(\n",
    "    file=str(datasets_folder / \"dataset_double_pendulum_train.npz\"), **training_dataset\n",
    ")\n",
    "jnp.savez(\n",
    "    file=str(datasets_folder / \"dataset_double_pendulum_test.npz\"), **test_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787efebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_distribution(_theta):\n",
    "    bin_no = 20\n",
    "    heatmap, xedges, yedges = onp.histogram2d(_theta[:, 0], _theta[:, 1], bins=bin_no)\n",
    "    extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]\n",
    "    plt.clf()\n",
    "    plt.imshow(heatmap.T, extent=extent)\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(\"Link 1 angles (rad)\")\n",
    "    plt.ylabel(\"Link 2 angles (rad)\")\n",
    "    plt.title(\"Heat map of sample frequency in the state space\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c627696",
   "metadata": {},
   "source": [
    "## Lets see what data we have got\n",
    "\n",
    "Run the cells below to see the distribution of the train and test data set angles over the state space. You can see the training set has a far higher number of samples in some areas compared to others while the test set is evenly spread out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655f3841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the distribution of training samples in the state space\n",
    "data_distribution(training_dataset[\"th_curr_ss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ade08df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shows the distribution of test samplesin the state space\n",
    "data_distribution(test_dataset[\"th_curr_ss\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8648d0",
   "metadata": {},
   "source": [
    "Run the cells below to show what the rendered image of the robot actually looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ee5ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a random image from the training dataset\n",
    "index = onp.random.randint(0, num_samples_train)\n",
    "print(\"index\", index)\n",
    "print(\"theta: \", training_dataset[\"th_curr_ss\"][index])\n",
    "plt.imshow(training_dataset[\"th_pix_curr\"][index, :, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e5e3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a random image from the test dataset\n",
    "index = onp.random.randint(0, 180 * 180)\n",
    "print(\"index\", index)\n",
    "print(\"theta: \", test_dataset[\"th_curr_ss\"][index])\n",
    "plt.imshow(test_dataset[\"th_pix_curr\"][index, :, :, :])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
